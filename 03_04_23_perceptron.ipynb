{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQNQ/uutqVCudyUdSP8FLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murpunk/Programming_2023/blob/main/03_04_23_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Список литературы"
      ],
      "metadata": {
        "id": "aE09W2JgUkf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  К.В. Воронцов Математические методы обучения по прецедентам (теория \n",
        "обучения машин). 141 с. (Voron-ML-1.pdf)\n",
        "2.  Машинное обучение (курс лекций, К.В.Воронцов): Линейный классификатор (machinelearning.ru), Метод стохастического градиента \n",
        "(machinelearning.ru) (“Линейные методы классификации и регрессии: метод \n",
        "стохастического градиента”: https://www.youtube.com/watch?v=thrPR77K-os)\n",
        "3.  Рашка Себастьян, Мирджалили Вахид. Python и машинное обучение: машинное и глубокое обучение с использованием Python, scikit-learn и \n",
        "TensorFlow 2, 3-е изд.: Пер. с англ. СПб. : ООО \"Диалектика\", 2020. 848 с.\n",
        "4.  Андреас Мюллер, Сара Гвидо. Введение в машинное обучение с помощью \n",
        "Python. Руководство для специалистов по работе с данными. 393 с."
      ],
      "metadata": {
        "id": "hrkMn_2sUphu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подробней см. в [1, стр. 51–62], [2], [3, стр. 49–84], [4]."
      ],
      "metadata": {
        "id": "jBMuM_wuY-M2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Документация:\n",
        "*  1.1. Linear Models — scikit-learn 1.1.3 documentation\n",
        "*  1.5. Stochastic Gradient Descent — scikit-learn 1.1.3 documentation\n",
        "*  sklearn.linear_model.LinearRegression — scikit-learn 1.1.3 documentation\n",
        "*  sklearn.linear_model.Perceptron — scikit-learn 1.1.3 documentation"
      ],
      "metadata": {
        "id": "iGW6uNSEZHC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Прочитайте пункт “Линейные методы регрессии и классификации” и рекомендованную литературу к нему и ответьте на вопросы"
      ],
      "metadata": {
        "id": "Hwrp8c-MSQa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) В каком виде ищется решение в задаче восстановления регрессии? На что влияет коэффициент $w_0$?"
      ],
      "metadata": {
        "id": "jdVODzXgSaKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В задаче восстановления регрессии решение ищется в виде линейной функции — взвешенной суммы всех признаков: суммы всех признаков $f_i(x)$ с коэффицентами $w_i$, где $x$ входит в обучающую выборку.\n",
        "\n",
        "$w_0$ — это дополнительный коэффицент, который смещает линейную функцию относительно начала координат.\n",
        "\n",
        "Линейная модель восстановления регрессии в виде функции: $a(x, w) = \\displaystyle\\sum_{j=1}^{n} f_j(x)w_j + w_0$"
      ],
      "metadata": {
        "id": "3M4klOTBT8XB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Какой вид имеет функция потерь в методе наименьших квадратов?"
      ],
      "metadata": {
        "id": "aaeyevwJT96h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Квадратичная функция потерь для каждой i-ой точки выглядит следующим образом:\n",
        "\n",
        "\n",
        "$L(a, y) = (a_i - y_i)^2$, где $a$ — истинное значение выхода модели, а $y$ — фактический выход модели.\n",
        "\n",
        "Если просуммировать значения функции потерь, получится функционал качества:\n",
        "\n",
        "\n",
        "$Q(w) = \\displaystyle\\sum_{i=1}^{l} (a(x_i, w) - y_i)^2 \\to {\\underset{w}{min}}$\n",
        " \n",
        "Он такой же, как в методе наименьших квадратов. Параметры регрессионной модели вычисляются таким образом, чтобы сумма квадратов расстояний от линии регрессии до фактических значений данных была минимальной."
      ],
      "metadata": {
        "id": "C5wFAqcEUCDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Как в методе наименьших квадратов находится минимум?"
      ],
      "metadata": {
        "id": "O1SruOIdUDXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В методе наименьших квадратов функционал качества сводится к нахождению минимума этой функции при условии равенства всех производных нулю. После дифференцирования задача сводится к решению СЛАУ, из которой находятся неизвестные коэффициенты $w_i$."
      ],
      "metadata": {
        "id": "4NLotKu3UGap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) В каком виде ищется решение в задаче классификации? Какой геометрический смысл вектора коэффициентов $w$?"
      ],
      "metadata": {
        "id": "PJVdKsoAUHaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В задаче классификации решение ищется в виде функции знака числа от суммы всех  признаков $f_j(x)$ с коэффицентами $w_i$:\n",
        "\n",
        "$a(x, w) = sign \\langle x, w \\rangle = sign\\left(\\displaystyle\\sum_{j=1}^{n} f_j(x)w_j\\right)$\n",
        "\n",
        "Геометрический смысл состоит в том, что направляющий вектор коэффициентов $w$ разделяет гиперплоскость на два класса. Если точка лежит по одну сторону с вектором от гиперплоскости, то скалярное произведение будет больше нуля и точка попадает в класс +1. Если же лежит по другую сторону от вектора от гиперплоскости, то знак скалярного произведения меньше нуля и точка попадает в класс –1."
      ],
      "metadata": {
        "id": "wi5Oz0ZZUPWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) В чем недостаток использования пороговой функции потерь?"
      ],
      "metadata": {
        "id": "ZWRptg90UQcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пороговая функция потерь — это функция потерь, которая используется в задачах классификации и оптимизации. \n",
        "\n",
        "Недостатком пороговой функции потерь является то, что оне дифференцируема в некоторых точках. Это затрудняет её использование в некоторых алгоритмах, так как она не говорит о величине ошибки, функционал качества становится кусочной функцией."
      ],
      "metadata": {
        "id": "EXPw_4zEUVkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) Что такое отступ? Когда он бывает положительным и отрицательным? Какую еще информацию можно узнать с помощью него?"
      ],
      "metadata": {
        "id": "VMPWYS18UX0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вместо функции потерь используется её непрерывные аппроксимации:\n",
        "\n",
        "$L(a, y) = [\\langle x_i, w \\rangle y_i < 0] \\leqslant L(\\langle x_i, w \\rangle y_i)$,\n",
        "\n",
        "где $\\langle x_i, w \\rangle y_i$ — это $M_i(w)$, то есть отступ объекта $x_i$. Если нет ошибки, то отступ становится положительным, а пороговая функция потерь становится равной 0. Если есть ошибка, отступ становится отрицательным, тогда пороговая функция потерь становится равной 1.\n",
        "\n",
        "Отступ также говорит о расстоянии точки от гиперплоскости: чем дальше точка от гиперплоскости, тем больше модуль отступа."
      ],
      "metadata": {
        "id": "3Fzbt2h5Uc3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7) Какие бывают функции потерь?"
      ],
      "metadata": {
        "id": "12KMl1l2Ud__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чаще всего используются следующие функции потерь: простая, квадратичная и двоичная."
      ],
      "metadata": {
        "id": "NR7OxFGRUhXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Прочитайте пункт “Метод стохастического градиента” и рекомендованную литературу к нему и ответьте на вопросы"
      ],
      "metadata": {
        "id": "IzVTuWikU5tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) В чем отличия метода стохастического градиента от метода градиентного спуска?"
      ],
      "metadata": {
        "id": "C5MTOOeZWKfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метод градиентного спуска работает так: выбирается начальная точка, в которой считается значение градиента, показывающий направление роста функции потерь в начальной точке, и делается шаг в противоположном градиенту направлении. Таким образом можно найти локальный минимум.\n",
        "\n",
        "Стохастический градиентный спуск выбирает на каждом шаге случайный обучающий пример и вычисляет градиент функции потерь только по нему, а не как сумма градиентов от каждого элемента выборки. Так повышается сходимость алгоритма."
      ],
      "metadata": {
        "id": "F4nngHwCWQwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Зачем делается регуляризация?"
      ],
      "metadata": {
        "id": "729sNFSoWR0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Основным способом уменьшить переобучение является регуляризация, т.е. сокращение весов. За увеличение вектора весов применяется штраф, тогда функция потерь будет выглядеть следующим образом:\n",
        "\n",
        "$Q(w) = \\dfrac{1}{l} \\displaystyle\\sum_{j=1}^{l}L(\\langle x_i, w\\rangle y_i) + \\dfrac{\\tau}{2} \\sum\\limits_{j=1}^nw_j^2 \\rightarrow \\min\\limits_w$, где $\\tau$ $-$ коэффициент регуляризации."
      ],
      "metadata": {
        "id": "SfBWG3aqWVQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Какие параметры можно задавать в методе стохастического градиента?"
      ],
      "metadata": {
        "id": "a2GaxEc2WWeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В методе стохастического градиента можно задавать начальный вектор параметров $w$ и темп обучения $h$."
      ],
      "metadata": {
        "id": "d-cDqTqYWZZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Какие преимущества и недостатки метода стохастического градиента?"
      ],
      "metadata": {
        "id": "uT81fkE9Wauv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Преимущества**:\n",
        "*  метод легко реализуется;\n",
        "*  метод подходит для динамического обучения, когда данные поступают потоком, а не все сразу;\n",
        "*  случайной подвыборки может быть достаточно для обучения, поэтому веса можно настраивать для очень больших выборок (подходит для задач с большими данными).\n",
        "\n",
        "**Недостатки**:\n",
        "*  функционал качества может сходиться на локальном минимуме, а не на общем;\n",
        "*  возможно переобучение при маленькой обучающей выборке."
      ],
      "metadata": {
        "id": "3mPx27VEWfaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. В книге [3, на стр. 49–67] рассказывается о модели нейрона Мак-Каллока–Питтса (предложенной ими в 1943 г.) и о правиле обучения персептрона Фрэнк Розенблатт (1957 г.)"
      ],
      "metadata": {
        "id": "JeL8YyaWWnZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На стр. 56–67 написана реализация алгоритма обучения персептрона на Python в виде класса Perceptron и обучение его на наборе данных Iris. Скопируйте код из книги и повторите эксперименты из нее."
      ],
      "metadata": {
        "id": "soqZiSaiWvoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1zg4iaTMqoCp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "iris.data[:10]"
      ],
      "metadata": {
        "id": "pvn0c7sJrHxK",
        "outputId": "8c683362-d416-4078-8789-dddacaaf9399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.feature_names"
      ],
      "metadata": {
        "id": "h2wftX63v-8k",
        "outputId": "ccb5c92f-74e7-48a1-ea41-9b5a3a93afb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target_names"
      ],
      "metadata": {
        "id": "o4k_9PVgwDEJ",
        "outputId": "690841dc-416e-47fa-bf55-421e731bab80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target"
      ],
      "metadata": {
        "id": "F0-3xmTwwGC3",
        "outputId": "2d187ce5-68c1-4926-d5b1-c2f85ca1d187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(object):\n",
        "  def __init__ (self, eta = 0.01, n_iter = 50, random_state = 1):\n",
        "    self.eta = eta\n",
        "    self.n_iter = n_iter\n",
        "    self.random_state = random_state\n",
        "  def fit(self, X, y):\n",
        "    rgen = np.random.RandomState(self.random_state)\n",
        "    self.w_ = rgen.normal(loc = 0.0, scale = 0.01, size = 1 + X.shape[1])\n",
        "    self.errors_ = []\n",
        "\n",
        "    for _ in range(self.n_iter):\n",
        "      errors = 0\n",
        "      for xi, target in zip(X, y):\n",
        "        update = self.eta * (target - self.predict(xi))\n",
        "        self.w_[1:] += update * xi\n",
        "        self.w_[0] += update\n",
        "        errors += int(apdate != 0.0)\n",
        "      self.errors.append(errors)\n",
        "    return self\n",
        "\n",
        "  def net_input(self, X):\n",
        "    return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "  \n",
        "  def predict(self, X):\n",
        "    return np.where(self.net_input(X) >= 0.0, 1, -1)"
      ],
      "metadata": {
        "id": "lJlIk6vqsNSY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.data[:, [2, 3]]\n",
        "y = iris.target\n",
        "print('Class labels:', np.unique(y))"
      ],
      "metadata": {
        "id": "3wIne8dqvjCb",
        "outputId": "15cc9605-14e3-4d7d-e496-b812e7ce0684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class labels: [0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV. Выполните задание из файла statement-linear.pdf"
      ],
      "metadata": {
        "id": "4H-C4qILW5Bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Загрузите обучающую и тестовую выборки из файлов perceptron-train.csv и perceptron-test.csv. Целевая переменная записана в первом столбце, признаки — во втором и третьем"
      ],
      "metadata": {
        "id": "97jGo_7PW9tO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Sy026GAXjIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Обучите персептрон со стандартными параметрами и random_state=241"
      ],
      "metadata": {
        "id": "Z1jBTUS6Xjd_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSz7K6LlXnrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Подсчитайте качество (долю правильно классифицированных объектов, accuracy) полученного классификатора на тестовой выборке"
      ],
      "metadata": {
        "id": "HsFYYiAMXofP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PR9QMvg6Xt-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Нормализуйте обучающую и тестовую выборку с помощью класса StandardScaler"
      ],
      "metadata": {
        "id": "ruo7aWCsXu_v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EhkciXpHXz2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Обучите персептрон на новых выборках. Найдите долю правильных ответов на тестовой выборке"
      ],
      "metadata": {
        "id": "IIGeHZtjX0i3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "83Q7vzUUX5P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Найдите разность между качеством на тестовой выборке после нормализации и качеством до нее. Это число и будет ответом на задание"
      ],
      "metadata": {
        "id": "SJXxJceQX563"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1chwtJ6X_2H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}